---
title: Fisher
date: 2018-10-19 18:09:38
categories: 
    - 模式识别
tag: 
    - 模式识别
mathjax: true
---
线性判别方法linear discriminant analysis, LDA, R.A.

<!-- more --> 

# 线性判别函数

- 线性判别函数：$y = Wx$
- 样本向量：$W$
- 权值向量：$x$
- 决策面：$g(x) = g_1(x) - g_2(x) = 0$
- $x$到决策面$H$的距离：$g(x) / ||W||$

---
##  涉及多分类
1. 每一类别可用单个判别边界与其它类别相分开，各自确定边界：
  $$y = A*x，->solve$$ 

2. 每个模式类和其它模式类间可分别用判别平面分开，这样，有$M(M - 1)/2$个判别平面：
   - 判别函数： $g_{ij}(X) = w_{ij}^Tx$
   - 判别边界： $g_{ij}(x) = 0$
   - $$g_{ij}(x)>0, x\in \omega_1 \\  g_{ij}(x)<0, x \in \omega_2$$
   - **结论**：判别区间增大，不确定区间减少，比第一种情况小得多。

3. 每类都有一个判别函数, 存在M个判别函数
   - 判别函数：$g(x)=W_K^TX ,k=1,2,...,M$
   - 判别规则：$g_i(x)=W_i^TX , Max: x\in\omega_1 , samll other$
   - 判别边界：$g_i(x)=g_j(x) 或者 g_i(x)-g_j(x)=0$  
   - **优点**：考虑了相邻的判别函数，可以保证交于一点，不确定区间没有了，所以这种是最好情况。

--- 
## 广义线性判别函数
$$
g(x) = w1f1+w2f2+w3f3+......+wk 
$$
1. 这样一个非线性判别函数通过映射，变换成线性判别函数。
2. 原始的特征空间是非线性，
3. 但通过某种映射，在新的空间 能保证是线性函数

## 引入Fisher
1. 为了降维，降低计算复杂度
2. 易于分类
3. 使两类样本在该轴上投影之间的距离尽可能远，
4. 而每一类 样本的投影尽可能紧凑。
5. 评价标准
   - 类内离散度矩阵$S_w$
   - 类间离散度矩阵$S_b$

---
# Fisher

## Step
- step1：计算均值向量 $mean_1、mean_2、mean_3、...$
- step2：计算类内离散度矩阵$Si_1、Si_2、Si_3、...$
- step3：计算总样本类内离散度矩阵$S_w$
   - $S_w=Si_1+Si_2+Si_3+...$
- step4：计算样本类间离散度矩阵$S_b$，$Sb_{12}、Sb_{13}、Sb_{23}、...$
- step5：最佳投影方向
- step6：判别函数求阈值 $W_0$


## 缺点：
Fisher并没有考虑到数据的分布，假如数据不是正态分布的，甚至是多峰分布的，Fisher就瞎了，我认为这才是Fisher最大的问题。

## 改进 & 多分类
通过看书和查阅各种资料，改进/分类的核心思想其实就2点：

类间协方差矩阵的推广，Duda and Hart，1973
>Pattern Classification and Scene Analysis by Richard O. Duda and Peter E. Hart
>Michael Thompson
>Leonardo
>The MIT Press
>Volume 7, Number 4, Autumn 1974
>p. 370

判别准则选择，Fukunage，1990
>Introduction to Statistical Pattern Recognition Second Edition，1990.
>Keinosuke Fukunaga 
>0327.F85 1990. 006.4 - dc20. 89-18195. CIP.
$$
J(W)=Tr{S_W^{-1}S_B} \\
J(W)=Tr{(W^TS_WW)^{-1}(W^TS_WW)}
$$
其中，权值由$\{S_W^{-1}S_B\}$的d个特征值决定（降序，$d<D$）。

取d个最大的标准，D阶方阵的可以算出D个特征值，大多数都是复数，默认取为实数的特征值，再排序。


